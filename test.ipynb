{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "from code_completion_lib.imports.imports import Imports\n",
    "from code_completion_lib.parse_notebooks import Parser\n",
    "from code_completion_lib.methods.find_methods_in_code import Methods\n",
    "from code_completion_lib.logger.logger import Logger\n",
    "from code_completion_lib.code_completion import CodeCompletion\n",
    "import os\n",
    "from math import log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = Logger(__name__, mode=\"a\")\n",
    "logger.info(\"-----------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "size = [\"small\",\"medium\",\"big\"]\n",
    "path = \"C:\\data\\data_parsed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [4], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m     parcer \u001B[38;5;241m=\u001B[39m Parser(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mnotebooks\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mC:\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mdata\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124mdata_parsed\u001B[39m\u001B[38;5;124m'\u001B[39m, logger\u001B[38;5;241m=\u001B[39mlogger)\n\u001B[0;32m      3\u001B[0m     parcer\u001B[38;5;241m.\u001B[39mparse()\n\u001B[1;32m----> 4\u001B[0m     \u001B[43mparcer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcheck_language\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m      6\u001B[0m     logger\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mException\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\sasha\\code_completion\\code_completion_lib\\parse_notebooks.py:59\u001B[0m, in \u001B[0;36mParser.check_language\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     56\u001B[0m full_path: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparse_from, filename)\n\u001B[0;32m     58\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m---> 59\u001B[0m     notebook \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_notebook\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfull_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m notebook[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkernelspec\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlanguage\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlanguages:\n\u001B[0;32m     62\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mlanguages[notebook[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmetadata\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mkernelspec\u001B[39m\u001B[38;5;124m'\u001B[39m][\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlanguage\u001B[39m\u001B[38;5;124m'\u001B[39m]] \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32mD:\\sasha\\code_completion\\code_completion_lib\\parse_notebooks.py:24\u001B[0m, in \u001B[0;36mParser._get_notebook\u001B[1;34m(self, notebook_path)\u001B[0m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_get_notebook\u001B[39m(\u001B[38;5;28mself\u001B[39m, notebook_path: \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m---> 24\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mnotebook_path\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mr\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mas\u001B[39;00m notebook:\n\u001B[0;32m     25\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     26\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m json\u001B[38;5;241m.\u001B[39mload(notebook, strict\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\codecs.py:309\u001B[0m, in \u001B[0;36mBufferedIncrementalDecoder.__init__\u001B[1;34m(self, errors)\u001B[0m\n\u001B[0;32m    303\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mBufferedIncrementalDecoder\u001B[39;00m(IncrementalDecoder):\n\u001B[0;32m    304\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    305\u001B[0m \u001B[38;5;124;03m    This subclass of IncrementalDecoder can be used as the baseclass for an\u001B[39;00m\n\u001B[0;32m    306\u001B[0m \u001B[38;5;124;03m    incremental decoder if the decoder must be able to handle incomplete\u001B[39;00m\n\u001B[0;32m    307\u001B[0m \u001B[38;5;124;03m    byte sequences.\u001B[39;00m\n\u001B[0;32m    308\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 309\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, errors\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstrict\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m    310\u001B[0m         IncrementalDecoder\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, errors)\n\u001B[0;32m    311\u001B[0m         \u001B[38;5;66;03m# undecoded input that is kept between calls to decode()\u001B[39;00m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "try:\n",
    "    parcer = Parser(r'C:\\data\\notebooks', r'C:\\data\\data_parsed', logger=logger)\n",
    "    parcer.parse()\n",
    "    parcer.check_language()\n",
    "except Exception:\n",
    "    logger.error(\"Exception\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in size:\n",
    "    try:\n",
    "        imports = Imports(os.path.join(path, name),size=name,logger=logger)\n",
    "        imports.process()\n",
    "    except Exception:\n",
    "        logger.error(\"Exception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in size:\n",
    "    try:\n",
    "        completion = CodeCompletion(size=name, logger=logger)\n",
    "        completion.import_clusterization()\n",
    "    except Exception:\n",
    "        logger.error(\"Exception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [4], line 5\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m      4\u001B[0m     methods \u001B[38;5;241m=\u001B[39m Methods(os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(path, name),size\u001B[38;5;241m=\u001B[39mname, logger\u001B[38;5;241m=\u001B[39mlogger)\n\u001B[1;32m----> 5\u001B[0m     \u001B[43mmethods\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfind_methods\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel_path\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m:\n\u001B[0;32m      7\u001B[0m         logger\u001B[38;5;241m.\u001B[39merror(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mException\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\sasha\\code_completion\\code_completion_lib\\methods\\find_methods_in_code.py:106\u001B[0m, in \u001B[0;36mMethods.find_methods\u001B[1;34m(self, model_path)\u001B[0m\n\u001B[0;32m    104\u001B[0m     expr \u001B[38;5;241m=\u001B[39m [exp[\u001B[38;5;241m0\u001B[39m], exp[\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mreplace(method[\u001B[38;5;241m1\u001B[39m], method[\u001B[38;5;241m0\u001B[39m])]\n\u001B[0;32m    105\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m index \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(length):\n\u001B[1;32m--> 106\u001B[0m         expr\u001B[38;5;241m.\u001B[39mappend(\u001B[43mcompletion\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcluster_predict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimports_only_lib\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmodels\u001B[49m\u001B[43m[\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m    107\u001B[0m     expr_full\u001B[38;5;241m.\u001B[39mappend(expr)\n\u001B[0;32m    109\u001B[0m result\u001B[38;5;241m.\u001B[39mextend(expr_full)\n",
      "File \u001B[1;32mD:\\sasha\\code_completion\\code_completion_lib\\code_completion.py:345\u001B[0m, in \u001B[0;36mCodeCompletion.cluster_predict\u001B[1;34m(self, imports, model)\u001B[0m\n\u001B[0;32m    342\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    343\u001B[0m         X[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mappend(\u001B[38;5;241m0\u001B[39m)\n\u001B[1;32m--> 345\u001B[0m predict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCLUSTER_\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpredict[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_nearest_centroid.py:237\u001B[0m, in \u001B[0;36mNearestCentroid.predict\u001B[1;34m(self, X)\u001B[0m\n\u001B[0;32m    233\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[0;32m    235\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_data(X, accept_sparse\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcsr\u001B[39m\u001B[38;5;124m\"\u001B[39m, reset\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m    236\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_[\n\u001B[1;32m--> 237\u001B[0m     \u001B[43mpairwise_distances_argmin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcentroids_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    238\u001B[0m ]\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py:795\u001B[0m, in \u001B[0;36mpairwise_distances_argmin\u001B[1;34m(X, Y, axis, metric, metric_kwargs)\u001B[0m\n\u001B[0;32m    792\u001B[0m         metric \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msqeuclidean\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    793\u001B[0m         metric_kwargs \u001B[38;5;241m=\u001B[39m {}\n\u001B[1;32m--> 795\u001B[0m     indices \u001B[38;5;241m=\u001B[39m \u001B[43mArgKmin\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    796\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    797\u001B[0m \u001B[43m        \u001B[49m\u001B[43mY\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    798\u001B[0m \u001B[43m        \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    799\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    800\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetric_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    801\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mauto\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m    802\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_distance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    803\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    804\u001B[0m     indices \u001B[38;5;241m=\u001B[39m indices\u001B[38;5;241m.\u001B[39mflatten()\n\u001B[0;32m    805\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    806\u001B[0m     \u001B[38;5;66;03m# Joblib-based backend, which is used when user-defined callable\u001B[39;00m\n\u001B[0;32m    807\u001B[0m     \u001B[38;5;66;03m# are passed for metric.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    813\u001B[0m     \u001B[38;5;66;03m# Turn off check for finiteness because this is costly and because arrays\u001B[39;00m\n\u001B[0;32m    814\u001B[0m     \u001B[38;5;66;03m# have already been validated.\u001B[39;00m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_pairwise_distances_reduction\\_dispatcher.py:277\u001B[0m, in \u001B[0;36mArgKmin.compute\u001B[1;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001B[0m\n\u001B[0;32m    196\u001B[0m \u001B[38;5;124;03m\"\"\"Compute the argkmin reduction.\u001B[39;00m\n\u001B[0;32m    197\u001B[0m \n\u001B[0;32m    198\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    274\u001B[0m \u001B[38;5;124;03mreturns.\u001B[39;00m\n\u001B[0;32m    275\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    276\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m X\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m Y\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mfloat64:\n\u001B[1;32m--> 277\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mArgKmin64\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcompute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    278\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    279\u001B[0m \u001B[43m        \u001B[49m\u001B[43mY\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mY\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    280\u001B[0m \u001B[43m        \u001B[49m\u001B[43mk\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mk\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    281\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    282\u001B[0m \u001B[43m        \u001B[49m\u001B[43mchunk_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mchunk_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    283\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetric_kwargs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetric_kwargs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    284\u001B[0m \u001B[43m        \u001B[49m\u001B[43mstrategy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mstrategy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    285\u001B[0m \u001B[43m        \u001B[49m\u001B[43mreturn_distance\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreturn_distance\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    286\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    288\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m X\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m Y\u001B[38;5;241m.\u001B[39mdtype \u001B[38;5;241m==\u001B[39m np\u001B[38;5;241m.\u001B[39mfloat32:\n\u001B[0;32m    289\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ArgKmin32\u001B[38;5;241m.\u001B[39mcompute(\n\u001B[0;32m    290\u001B[0m         X\u001B[38;5;241m=\u001B[39mX,\n\u001B[0;32m    291\u001B[0m         Y\u001B[38;5;241m=\u001B[39mY,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    297\u001B[0m         return_distance\u001B[38;5;241m=\u001B[39mreturn_distance,\n\u001B[0;32m    298\u001B[0m     )\n",
      "File \u001B[1;32msklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx:76\u001B[0m, in \u001B[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin64.compute\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32msklearn\\metrics\\_pairwise_distances_reduction\\_argkmin.pyx:385\u001B[0m, in \u001B[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.EuclideanArgKmin64.__init__\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32msklearn\\metrics\\_pairwise_distances_reduction\\_base.pyx:115\u001B[0m, in \u001B[0;36msklearn.metrics._pairwise_distances_reduction._base._sqeuclidean_row_norms64\u001B[1;34m()\u001B[0m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\_base.py:1301\u001B[0m, in \u001B[0;36misspmatrix\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m   1297\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1298\u001B[0m             \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39mzeros(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape, dtype\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdtype, order\u001B[38;5;241m=\u001B[39morder)\n\u001B[1;32m-> 1301\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21misspmatrix\u001B[39m(x):\n\u001B[0;32m   1302\u001B[0m     \u001B[38;5;124;03m\"\"\"Is x of a sparse matrix type?\u001B[39;00m\n\u001B[0;32m   1303\u001B[0m \n\u001B[0;32m   1304\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1326\u001B[0m \u001B[38;5;124;03m    False\u001B[39;00m\n\u001B[0;32m   1327\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m   1328\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x, spmatrix)\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for name in size:\n",
    "    model_path = rf'code_completion_lib\\models\\{name}'\n",
    "    try:\n",
    "        methods = Methods(os.path.join(path, name),size=name, logger=logger)\n",
    "        methods.find_methods(model_path)\n",
    "    except Exception:\n",
    "            logger.error(\"Exception\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def top_3(y_true, y_pred):\n",
    "    true = 0\n",
    "    length = len(y_pred)\n",
    "    if length == 0:\n",
    "        return 0\n",
    "    for i in range(len(y_pred)):\n",
    "        for j in range(len(y_pred[i])):\n",
    "            if j==3:\n",
    "                continue\n",
    "            if y_pred[i][j] == y_true[i]:\n",
    "                true+=1\n",
    "    return true/length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nDCG(y_true, y_pred):\n",
    "    relevance = []\n",
    "    length = len(y_pred)\n",
    "    if length == 0:\n",
    "        return 0\n",
    "    for i in range(len(y_pred)):\n",
    "        relevance.append([])\n",
    "        for j in range(3):\n",
    "            if j >= len(y_pred[i]):\n",
    "                relevance[i].append(0)\n",
    "            elif y_pred[i][j] == y_true[i]:\n",
    "                relevance[i].append(1)\n",
    "            else:\n",
    "                relevance[i].append(0)\n",
    "    ndcg = 0\n",
    "    for element in relevance:\n",
    "        ideal = element.copy()\n",
    "        ideal.sort(reverse=True)\n",
    "        dcg = 0\n",
    "        idcg = 0\n",
    "        for i in range(len(element)):\n",
    "            dcg += element[i]/log2(i+2)\n",
    "            idcg += ideal[i]/log2(i+2)\n",
    "        if idcg != 0:\n",
    "            ndcg += dcg/idcg\n",
    "    ndcg /= len(relevance)\n",
    "    return ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(rf'code_completion_lib\\methods\\models\\small\\data_test.csv')\n",
    "length = dataset.shape[0]\n",
    "df1 = dataset.iloc [:int(0.7*length)]\n",
    "df2 = dataset.iloc [int(0.7*length):int(0.9*length)]\n",
    "df3 = dataset.iloc [int(0.9*length):]\n",
    "df1.to_csv(r'code_completion_lib\\data_train.csv',index=False)\n",
    "df2.to_csv(r'code_completion_lib\\data_valid.csv',index=False)\n",
    "df3.to_csv(r'code_completion_lib\\data_test.csv',index=False)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: small\n",
      "AffinityPropagation(damping=0.999, random_state=0)\n",
      "top 1 accuracy: 0.5\n",
      "top 3 accuracy: 0.5\n",
      "ndcg: 0.5\n",
      "\n",
      "default top 1 accuracy: 0.5\n",
      "default top 3 accuracy: 0.5\n",
      "default ndcg: 0.5\n",
      "\n",
      "    CLUSTER_30:\n",
      "        size: 50.00 \n",
      "        top 1 accuracy: 0.0\n",
      "        top 3 accuracy: 0.0\n",
      "        ndcg: 0.0\n",
      "\n",
      "    CLUSTER_28:\n",
      "        size: 50.00 \n",
      "        top 1 accuracy: 1.0\n",
      "        top 3 accuracy: 1.0\n",
      "        ndcg: 1.0\n",
      "\n",
      "AgglomerativeClustering(metric='euclidean', n_clusters=13)\n",
      "top 1 accuracy: 0.5\n",
      "top 3 accuracy: 0.5\n",
      "ndcg: 0.5\n",
      "\n",
      "default top 1 accuracy: 0.5\n",
      "default top 3 accuracy: 0.5\n",
      "default ndcg: 0.5\n",
      "\n",
      "    CLUSTER_5:\n",
      "        size: 50.00 \n",
      "        top 1 accuracy: 0.0\n",
      "        top 3 accuracy: 0.0\n",
      "        ndcg: 0.0\n",
      "\n",
      "    CLUSTER_12:\n",
      "        size: 50.00 \n",
      "        top 1 accuracy: 1.0\n",
      "        top 3 accuracy: 1.0\n",
      "        ndcg: 1.0\n",
      "\n",
      "KMeans(n_clusters=13, n_init='auto', random_state=0)\n",
      "top 1 accuracy: 0.5\n",
      "top 3 accuracy: 0.5\n",
      "ndcg: 0.5\n",
      "\n",
      "default top 1 accuracy: 0.5\n",
      "default top 3 accuracy: 0.5\n",
      "default ndcg: 0.5\n",
      "\n",
      "    CLUSTER_0:\n",
      "        size: 50.00 \n",
      "        top 1 accuracy: 0.0\n",
      "        top 3 accuracy: 0.0\n",
      "        ndcg: 0.0\n",
      "\n",
      "    CLUSTER_11:\n",
      "        size: 50.00 \n",
      "        top 1 accuracy: 1.0\n",
      "        top 3 accuracy: 1.0\n",
      "        ndcg: 1.0\n",
      "\n",
      "MeanShift(bandwidth=2.3)\n",
      "top 1 accuracy: 0.5\n",
      "top 3 accuracy: 0.5\n",
      "ndcg: 0.5\n",
      "\n",
      "default top 1 accuracy: 0.5\n",
      "default top 3 accuracy: 0.5\n",
      "default ndcg: 0.5\n",
      "\n",
      "    CLUSTER_0:\n",
      "        size: 50.00 \n",
      "        top 1 accuracy: 0.0\n",
      "        top 3 accuracy: 0.0\n",
      "        ndcg: 0.0\n",
      "\n",
      "    CLUSTER_31:\n",
      "        size: 50.00 \n",
      "        top 1 accuracy: 1.0\n",
      "        top 3 accuracy: 1.0\n",
      "        ndcg: 1.0\n",
      "\n",
      "SpectralClustering(assign_labels='discretize', n_clusters=13, random_state=0)\n",
      "top 1 accuracy: 0.5\n",
      "top 3 accuracy: 0.5\n",
      "ndcg: 0.5\n",
      "\n",
      "default top 1 accuracy: 0.5\n",
      "default top 3 accuracy: 0.5\n",
      "default ndcg: 0.5\n",
      "\n",
      "    CLUSTER_1:\n",
      "        size: 50.00 \n",
      "        top 1 accuracy: 0.0\n",
      "        top 3 accuracy: 0.0\n",
      "        ndcg: 0.0\n",
      "\n",
      "    CLUSTER_9:\n",
      "        size: 50.00 \n",
      "        top 1 accuracy: 1.0\n",
      "        top 3 accuracy: 1.0\n",
      "        ndcg: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for name in size:\n",
    "    print(f\"size: {name}\")\n",
    "    dataset = pd.read_csv(rf'code_completion_lib\\methods\\models\\{name}\\data_test.csv')\n",
    "    for line in dataset.values:\n",
    "        line[1] = line[1].split(\"(\",1)[0]\n",
    "    models = dataset.keys()[2:]\n",
    "    for model in models:\n",
    "        completion_with_clusters = []\n",
    "        print(model)\n",
    "        try:\n",
    "            X = dataset[[\"varible_name\", model]]\n",
    "            y = dataset[[\"method\"]]\n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)\n",
    "            completion = CodeCompletion(size=name, logger=logger)\n",
    "            completion.relations_variable_with_method(X_train, y_train, model=model)\n",
    "            completion.relations_cluster_with_variable(X_train, y_train, model=model)\n",
    "            completion.default_task(X_train, y_train)\n",
    "\n",
    "\n",
    "            y_pred_top1 = []\n",
    "            y_pred_top3 = []\n",
    "            default_y_pred_top1 = []\n",
    "            default_y_pred_top3 = []\n",
    "            y_true = y_test['method'].values.tolist()\n",
    "            for index in range(X_test.shape[0]):\n",
    "                cluster = X_test.values[index][1]\n",
    "                variable_name = X_test.values[index][0]\n",
    "\n",
    "                f_completion = completion.get_function_completion(model=model, variable_name=variable_name,cluster=cluster,number=3)\n",
    "                default_f_completion = completion.get_default_function_completion(variable_name=variable_name, number=3)\n",
    "\n",
    "\n",
    "                completion_with_clusters.append([cluster, f_completion])\n",
    "\n",
    "                y_pred_top1.append(f_completion[0])\n",
    "                y_pred_top3.append(f_completion)\n",
    "                default_y_pred_top1.append(default_f_completion[0])\n",
    "                default_y_pred_top3.append(default_f_completion)\n",
    "\n",
    "\n",
    "            acc_top1 = accuracy_score(y_true, y_pred_top1)\n",
    "            acc_top3 = top_3(y_true, y_pred_top3)\n",
    "            ndcg = nDCG(y_true, y_pred_top3)\n",
    "\n",
    "            default_acc_top1 = accuracy_score(y_true, default_y_pred_top1)\n",
    "            default_acc_top3 = top_3(y_true, default_y_pred_top3)\n",
    "            default_ndcg = nDCG(y_true, default_y_pred_top3)\n",
    "\n",
    "            print(f\"top 1 accuracy: {acc_top1}\")\n",
    "            print(f\"top 3 accuracy: {acc_top3}\")\n",
    "            print(f\"ndcg: {ndcg}\\n\")\n",
    "\n",
    "            print(f\"default top 1 accuracy: {default_acc_top1}\")\n",
    "            print(f\"default top 3 accuracy: {default_acc_top3}\")\n",
    "            print(f\"default ndcg: {default_ndcg}\\n\")\n",
    "\n",
    "            clusters = {}\n",
    "            true_cl = {}\n",
    "\n",
    "            clusters_top3 = {}\n",
    "\n",
    "            for index in range(X_test.shape[0]):\n",
    "                clusters[completion_with_clusters[index][0]] = []\n",
    "                true_cl[completion_with_clusters[index][0]] = []\n",
    "                clusters_top3[completion_with_clusters[index][0]] = []\n",
    "\n",
    "            for index in range(X_test.shape[0]):\n",
    "\n",
    "                tmp = clusters[completion_with_clusters[index][0]]\n",
    "                tmp.append(y_pred_top1[index])\n",
    "                clusters[completion_with_clusters[index][0]] = tmp\n",
    "\n",
    "                tmp_true = true_cl[completion_with_clusters[index][0]]\n",
    "                tmp_true.append(y_true[index])\n",
    "                true_cl[completion_with_clusters[index][0]] = tmp_true\n",
    "\n",
    "\n",
    "                tmp_top3 = clusters_top3[completion_with_clusters[index][0]]\n",
    "                tmp_top3.append(y_pred_top3[index])\n",
    "                clusters_top3[completion_with_clusters[index][0]] = tmp_top3\n",
    "\n",
    "\n",
    "            for key in clusters.keys():\n",
    "                print(f\"    {key}:\")\n",
    "                acc_top1 = accuracy_score(true_cl[key], clusters[key])\n",
    "                acc_top3 = top_3(true_cl[key], clusters_top3[key])\n",
    "                ndcg = nDCG(true_cl[key], clusters_top3[key])\n",
    "                cluster_size = len(true_cl[key])/len(y_true)*100\n",
    "                print('        size: %.2f ' % cluster_size)\n",
    "                print(f\"        top 1 accuracy: {acc_top1}\")\n",
    "                print(f\"        top 3 accuracy: {acc_top3}\")\n",
    "                print(f\"        ndcg: {ndcg}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "        except Exception:\n",
    "            logger.error(\"Exception\")\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
